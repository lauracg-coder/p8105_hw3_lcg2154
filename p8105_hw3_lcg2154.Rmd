---
title: "Homework 3 Solutions"
author: Laura Gomez
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(p8105.datasets)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = 0.6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

```{r}
data("instacart")
```

This data set contains `r nrow(instacart)` rows and ... columns. 

Observations are the level of items in orders by user. There are user/order variables -- user ID, order ID, order day, and order hour. There are also item variables -- name, aisle, department, and some numeric codes. 

How many aisles are there, and which aisles are the most items ordered from?
```{r}
instacart %>%
  count(aisle) %>%
  arrange(desc(n))
```

Let's make a plot 
```{r}
instacart %>%
  count(aisle) %>%
  filter(n > 10000) %>%
  mutate(
    aisle = factor(aisle),
    aisle = fct_reorder(aisle, n)
  ) %>%
  ggplot(aes(x = aisle, y = n)) +
  geom_point() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

Make a table !
```{r}
instacart %>%
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>%
  group_by(aisle) %>%
  count(product_name) %>%
  mutate(rank = min_rank(desc(n))) %>%
  filter(rank < 4) %>%
  arrange(aisle, rank) %>%
  knitr::kable()
```

Apples vs. ice cream..
```{r}
instacart %>%
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>%
  group_by(product_name, order_dow) %>%
  summarize(mean_hour = mean(order_hour_of_day)) %>%
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour
  )
```


## Problem 2

Import and clean the accelerometer dataset. After data is tidy, add the *weekday vs weekend* variable and encode data with reasonable variable classes.
```{r accelerometer_tidy_df}
accelerometer_df = read_csv("./Data/accel_data.csv") %>%
  janitor::clean_names() %>%
  drop_na()  %>%
  pivot_longer(activity_1:activity_1440, names_to = 'time', names_prefix = 'activity_', values_to = 'activity_count') %>% 
  mutate(
    day = as.factor(day), 
    time = as.numeric(time)) %>% 
  mutate(
    weekend = ifelse(day == c("Saturday", "Sunday"),1,0), 
    weekend = case_when(weekend == 1 ~ "weekend", weekend == 0 ~ "weekday" )) %>%
  mutate(
    day = forcats::fct_relevel(
      day, "Monday", "Tuesday","Wednesday", "Thursday", "Friday", "Saturday", "Sunday" ))
```
**Accelerometers Data Description**:
The Accelerometers data set contains device obtained information measuring activity within a one minute interval for a 24 hour cycle starting at midnight.  The following variables exist in the data set `r ls(accelerometer_df)`. There are a total of `r nrow(accelerometer_df)` rows and `r ncol(accelerometer_df)` columns in our final data set. 

Using your tidied data set, aggregate across minutes to create a total activity variable for each day, and create a table showing these totals. Are any trends apparent?
```{r total activity_df}
 accelerometer_df %>% 
  group_by(week,day) %>% 
  summarize(total_activity_df = sum(activity_count, na.rm = TRUE)) %>% 
pivot_wider(names_from = "day", 
  values_from = "total_activity_df") %>%
  knitr::kable() 
# Talk more about trends
```
**Total Activity Data Trend**:
Based on the table above, there seems to be a trend in increase of activity on weekends in the beginning weeks (week 1 and 2). Then the values begin to increase significantly during the weekdays in subsequent weeks. Overall there is indirect proportional relationship between weekdays and weekend: as activity count increases during the weekends, the activity count of weekdays decreases and vice-versa. 

Make a single-panel plot that shows the 24-hour activity time courses for each day and use color to indicate day of the week. Describe in words any patterns or conclusions you can make based on this graph.
```{r}
accelerometer_df %>%
  ggplot(aes(x = time, y = activity_count, color = day)) + 
  geom_line(size = 1.5) +
  #geom_smooth(aes(group = day), se = FALSE) +
  labs(
    title = "24hr activity time colored by day of the week",
    x = " Activity time (minutes)",
    y = "Activity Count ")
#fix by aesthetics, add more transparency 
# talk more about trends
```
**Description** 
Based on the single-panel plot above, we observe a greater activity count on days like Saturday and Sunday. The overall activity count seems to increase for most days, including weekdays, later in the 24-hour activity cycle around minute 1400. 

## Problem 3

Import data
```{r}
library(p8105.datasets)
data("ny_noaa")
```
Write a short description of the data set, noting the size and structure of the data, describing some key variables, and indicating the extent to which missing data is an issue.
```{r}
ny_noaa_df = ny_noaa %>% separate('date', c( 'year','month','day')) %>% 
  mutate(
    day = factor(day), 
    prcp =  prcp/10,
    prcp = as.integer(prcp), 
    tmax = as.numeric(tmax), 
    tmin = as.numeric(tmin), 
    tmax = tmax/10,
    tmin = tmin/10) %>% 
  drop_na()
# for snowfall what are the most commonly observed values? do count from first problem
```

The data set drew information from the National Oceanic and Atmospheric Association (NOAA) to report on 5 variables, `r ls(ny_noaa_df)`, for New York State Weather Stations from January 1, 1981 through December 31, 2010. There are a total of `r nrow(ny_noaa_df)` rows and `rncol(ny_noaa_df)` columns in our final dataset. 

Make a two-panel plot showing the average max temperature in January and in July in each station across years. Is there any observable / interpretable structure? Any outliers?
```{r}
Jan_July_averagemax_df =  ny_noaa_df  %>% 
  group_by(month, year, id) %>% 
  filter(month %in% c("01","07")) %>% 
  summarize(average_tmax = mean(tmax)) %>% 
  mutate( year = as.numeric(year)) %>%
  ggplot(aes(x = year, y = average_tmax, group = id)) +
  geom_point() +
  geom_path() +
  facet_grid(~ month) +
  labs( 
     title = "Mean average temperature for January and July across stations and years", 
      x = "year", 
     y = "average max temperature(C)")
#structure is conserving between stations, one year warmer than other
```

Make a two-panel plot showing (i) tmax vs tmin for the full dataset (note that a scatterplot may not be the best option)
```{r}
tmax_tmin_df =
  ny_noaa_df %>%
  ggplot(aes(x = tmin, y = tmax)) + geom_hex()
```
(ii) make a plot showing the distribution of snowfall values greater than 0 and less than 100 separately by year.
```{r}
snowfall_df = 
  ny_noaa_df %>%
  drop_na() %>%
  filter( 'snow' > 0, 'snow' < 100 ) %>%
  ggplot(aes(x = year , y = snow, color = year)) +
  geom_boxplot() +
  labs( x = "Year", 
        y = "Snowfall Values (mm)")
```



